#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç‰¹å¾æå–å™¨
ä»æ¸…æ´—åçš„æ–‡æœ¬ä¸­æå–æœ‰ç”¨çš„ç‰¹å¾
"""

import re
import numpy as np
from typing import List, Dict, Tuple, Optional
from collections import Counter
import logging

logger = logging.getLogger(__name__)

class FeatureExtractor:
    """æ–‡æœ¬ç‰¹å¾æå–å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç‰¹å¾æå–å™¨"""
        # æŠ‘éƒç›¸å…³è¯æ±‡ï¼ˆåŸºäºPHQ-9é—®å·ï¼Œæ‰©å±•ç¤¾äº¤åª’ä½“è¡¨è¾¾ï¼‰
        self.depression_keywords = {
            'æƒ…ç»ªä½è½': [
                'sad', 'depressed', 'down', 'blue', 'unhappy', 'miserable', 'hopeless', 'sadness', 'depression',
                'drowning', 'sinking', 'drowning', 'suffocating', 'dying inside', 'dead inside', 'empty inside',
                'numb', 'feeling nothing', 'emotionally dead', 'broken', 'shattered', 'crushed', 'devastated',
                'heartbroken', 'soul crushing', 'mentally exhausted', 'emotionally drained', 'spirit broken',
                'feeling low', 'feeling down', 'feeling blue', 'feeling empty', 'feeling lost', 'feeling alone',
                'feeling worthless', 'feeling useless', 'feeling like a failure', 'feeling like a burden',
                'feeling like nobody cares', 'feeling like giving up', 'feeling like ending it all'
            ],
            'å…´è¶£ä¸§å¤±': [
                'uninterested', 'bored', 'no_interest', 'nothing_matters', 'empty', 'meaningless', 'pointless',
                'cant enjoy anything', 'nothing brings joy', 'nothing makes me happy', 'everything feels dull',
                'life is boring', 'life is meaningless', 'life has no purpose', 'life is pointless',
                'dont care about anything', 'dont want to do anything', 'dont feel like doing anything',
                'everything feels like a chore', 'nothing excites me', 'nothing motivates me',
                'lost interest in everything', 'lost passion', 'lost motivation', 'lost drive'
            ],
            'ç¡çœ é—®é¢˜': [
                'insomnia', 'sleep', 'tired', 'exhausted', 'fatigue', 'restless', 'cant_sleep', 'sleepless',
                'cant fall asleep', 'wake up in the middle of the night', 'sleep all day', 'oversleeping',
                'sleeping too much', 'sleeping too little', 'sleep problems', 'sleep issues',
                'mind racing at night', 'thoughts keeping me awake', 'anxiety keeping me awake',
                'depression keeping me awake', 'worrying all night', 'cant turn off my brain'
            ],
            'é£Ÿæ¬²å˜åŒ–': [
                'appetite', 'hungry', 'not_hungry', 'weight_loss', 'weight_gain', 'eating',
                'lost appetite', 'no appetite', 'dont feel like eating', 'forgetting to eat',
                'eating too much', 'emotional eating', 'stress eating', 'comfort eating',
                'food doesnt taste good', 'food has no flavor', 'eating alone', 'eating in bed'
            ],
            'æ³¨æ„åŠ›é—®é¢˜': [
                'concentrate', 'focus', 'attention', 'distracted', 'mind_wandering', 'racing_thoughts',
                'cant focus', 'cant concentrate', 'mind keeps wandering', 'thoughts all over the place',
                'brain fog', 'mental fog', 'cant think clearly', 'thoughts are scattered',
                'overthinking', 'ruminating', 'obsessive thoughts', 'intrusive thoughts',
                'mind wont stop', 'brain wont shut off', 'constant worrying', 'endless thoughts'
            ],
            'è‡ªæˆ‘è¯„ä»·': [
                'worthless', 'failure', 'useless', 'guilty', 'blame_myself', 'hate_myself', 'disappointment',
                'im a failure', 'im worthless', 'im useless', 'im a burden', 'im a disappointment',
                'im a waste of space', 'im a waste of oxygen', 'im a mistake', 'im a loser',
                'im not good enough', 'im not smart enough', 'im not pretty enough', 'im not worthy',
                'im a bad person', 'im a terrible person', 'im a horrible person', 'im a monster',
                'im a piece of shit', 'im garbage', 'im trash', 'im nothing', 'im nobody',
                'im invisible', 'im replaceable', 'im disposable', 'im forgettable'
            ],
            'è‡ªæ€æƒ³æ³•': [
                'suicide', 'kill_myself', 'death', 'die', 'end_it_all', 'better_off_dead', 'want_to_die', 'end_my_life',
                'want to die', 'want to end it all', 'want to kill myself', 'want to end my life',
                'thinking about suicide', 'thinking about death', 'thinking about dying',
                'wish i was dead', 'wish i could die', 'wish i was never born', 'wish i didnt exist',
                'life is not worth living', 'life has no value', 'life is meaningless',
                'everyone would be better off without me', 'nobody would miss me', 'nobody would care',
                'im better off dead', 'im better off not existing', 'im better off gone',
                'ending it all', 'ending my life', 'ending my suffering', 'ending my pain'
            ],
            'ç„¦è™‘ç—‡çŠ¶': [
                'anxious', 'worried', 'nervous', 'panic', 'fear', 'stress', 'anxiety',
                'constant anxiety', 'constant worry', 'constant fear', 'constant stress',
                'panic attacks', 'anxiety attacks', 'feeling overwhelmed', 'feeling suffocated',
                'feeling trapped', 'feeling stuck', 'feeling helpless', 'feeling hopeless',
                'feeling powerless', 'feeling out of control', 'feeling like im losing my mind',
                'feeling like im going crazy', 'feeling like im losing it', 'feeling like im breaking'
            ],
            'èº«ä½“ç—‡çŠ¶': [
                'pain', 'ache', 'sick', 'ill', 'headache', 'stomach', 'hurting',
                'constant pain', 'chronic pain', 'body aches', 'muscle pain', 'joint pain',
                'chest pain', 'heart pain', 'emotional pain', 'mental pain', 'psychological pain',
                'feeling sick', 'feeling ill', 'feeling unwell', 'feeling like im dying',
                'feeling like my body is shutting down', 'feeling like im falling apart'
            ],
            'ç¤¾äº¤é€€ç¼©': [
                'alone', 'lonely', 'isolated', 'no_friends', 'avoid_people', 'loneliness',
                'feeling alone', 'feeling lonely', 'feeling isolated', 'feeling disconnected',
                'feeling like nobody understands', 'feeling like nobody gets me', 'feeling like an outsider',
                'feeling like i dont belong', 'feeling like im different', 'feeling like im weird',
                'avoiding people', 'avoiding social situations', 'avoiding friends', 'avoiding family',
                'pushing people away', 'pushing everyone away', 'pushing loved ones away',
                'nobody wants to be around me', 'nobody likes me', 'nobody cares about me',
                'im a burden to others', 'im annoying to others', 'im toxic to others'
            ],
            'ä¼ªè£…ç—‡çŠ¶': [
                'fake smile', 'fakesmile', 'fake happy', 'pretending to be happy', 'pretending to be fine',
                'putting on a mask', 'wearing a mask', 'hiding my pain', 'hiding my sadness',
                'hiding my depression', 'hiding my anxiety', 'hiding my struggles', 'hiding my problems',
                'everyone thinks im fine', 'everyone thinks im happy', 'everyone thinks im okay',
                'nobody knows how i really feel', 'nobody knows my pain', 'nobody knows my struggles',
                'im good at pretending', 'im good at faking', 'im good at hiding', 'im good at masking',
                'smiling through the pain', 'laughing through the tears', 'happy on the outside, dying inside',
                'fine on the outside, broken inside', 'okay on the outside, not okay inside'
            ]
        }
        
        # æƒ…æ„Ÿè¯æ±‡ï¼ˆæ‰©å±•ç‰ˆï¼ŒåŒ…å«ç¤¾äº¤åª’ä½“è¡¨è¾¾ï¼‰
        self.emotion_words = {
            'positive': [
                'happy', 'joy', 'excited', 'love', 'great', 'wonderful', 'amazing', 'fantastic', 'blessed', 'grateful', 'optimistic', 'good', 'nice', 'perfect', 'awesome', 'brilliant', 'excellent', 'fixed', 'solved', 'better', 'relief', 'cheered', 'helped',
                'lol', 'haha', 'lmao', 'rofl', 'ğŸ˜‚', 'ğŸ˜Š', 'ğŸ˜„', 'ğŸ˜†', 'ğŸ˜‰', 'ğŸ˜', 'ğŸ˜‹', 'ğŸ˜', 'ğŸ¥°', 'ğŸ˜˜', 'ğŸ˜—', 'ğŸ˜™', 'ğŸ˜š', 'ğŸ™‚', 'ğŸ˜€', 'ğŸ˜ƒ', 'ğŸ˜„', 'ğŸ˜', 'ğŸ˜…', 'ğŸ¤£', 'ğŸ˜Š', 'ğŸ˜‡', 'ğŸ™ƒ', 'ğŸ˜‰', 'ğŸ˜Œ', 'ğŸ˜', 'ğŸ¥°', 'ğŸ˜˜', 'ğŸ˜—', 'ğŸ˜™', 'ğŸ˜š', 'ğŸ˜‹', 'ğŸ˜›', 'ğŸ˜', 'ğŸ˜œ', 'ğŸ¤ª', 'ğŸ¤¨', 'ğŸ§', 'ğŸ¤“', 'ğŸ˜', 'ğŸ¤©', 'ğŸ¥³', 'ğŸ˜', 'ğŸ˜’', 'ğŸ˜', 'ğŸ˜”', 'ğŸ˜Ÿ', 'ğŸ˜•', 'ğŸ™', 'â˜¹ï¸', 'ğŸ˜£', 'ğŸ˜–', 'ğŸ˜«', 'ğŸ˜©', 'ğŸ¥º', 'ğŸ˜¢', 'ğŸ˜­', 'ğŸ˜¤', 'ğŸ˜ ', 'ğŸ˜¡', 'ğŸ¤¬', 'ğŸ¤¯', 'ğŸ˜³', 'ğŸ¥µ', 'ğŸ¥¶', 'ğŸ˜±', 'ğŸ˜¨', 'ğŸ˜°', 'ğŸ˜¥', 'ğŸ˜“', 'ğŸ¤—', 'ğŸ¤”', 'ğŸ¤­', 'ğŸ¤«', 'ğŸ¤¥', 'ğŸ˜¶', 'ğŸ˜', 'ğŸ˜‘', 'ğŸ˜¯', 'ğŸ˜¦', 'ğŸ˜§', 'ğŸ˜®', 'ğŸ˜²', 'ğŸ¥±', 'ğŸ˜´', 'ğŸ¤¤', 'ğŸ˜ª', 'ğŸ˜µ', 'ğŸ¤', 'ğŸ¥´', 'ğŸ¤¢', 'ğŸ¤®', 'ğŸ¤§', 'ğŸ˜·', 'ğŸ¤’', 'ğŸ¤•', 'ğŸ¤‘', 'ğŸ¤ '
            ],
            'negative': [
                'sad', 'angry', 'frustrated', 'disappointed', 'hate', 'terrible', 'awful', 'horrible', 'hopeless', 'worthless', 'miserable', 'stressful', 'stress', 'anxiety', 'worried', 'scared', 'afraid', 'tired', 'exhausted', 'lonely', 'alone', 'useless', 'failure',
                'drowning', 'sinking', 'suffocating', 'dying inside', 'dead inside', 'empty inside', 'broken', 'shattered', 'crushed', 'devastated', 'heartbroken', 'soul crushing', 'mentally exhausted', 'emotionally drained', 'spirit broken',
                'ğŸ˜©', 'ğŸ˜¢', 'ğŸ˜­', 'ğŸ˜¤', 'ğŸ˜ ', 'ğŸ˜¡', 'ğŸ¤¬', 'ğŸ¤¯', 'ğŸ˜³', 'ğŸ¥µ', 'ğŸ¥¶', 'ğŸ˜±', 'ğŸ˜¨', 'ğŸ˜°', 'ğŸ˜¥', 'ğŸ˜“', 'ğŸ˜', 'ğŸ˜”', 'ğŸ˜Ÿ', 'ğŸ˜•', 'ğŸ™', 'â˜¹ï¸', 'ğŸ˜£', 'ğŸ˜–', 'ğŸ˜«', 'ğŸ˜©', 'ğŸ¥º', 'ğŸ˜¢', 'ğŸ˜­', 'ğŸ˜¤', 'ğŸ˜ ', 'ğŸ˜¡', 'ğŸ¤¬', 'ğŸ¤¯', 'ğŸ˜³', 'ğŸ¥µ', 'ğŸ¥¶', 'ğŸ˜±', 'ğŸ˜¨', 'ğŸ˜°', 'ğŸ˜¥', 'ğŸ˜“', 'ğŸ˜¶', 'ğŸ˜', 'ğŸ˜‘', 'ğŸ˜¯', 'ğŸ˜¦', 'ğŸ˜§', 'ğŸ˜®', 'ğŸ˜²', 'ğŸ¥±', 'ğŸ˜´', 'ğŸ¤¤', 'ğŸ˜ª', 'ğŸ˜µ', 'ğŸ¤', 'ğŸ¥´', 'ğŸ¤¢', 'ğŸ¤®', 'ğŸ¤§', 'ğŸ˜·', 'ğŸ¤’', 'ğŸ¤•'
            ],
            'neutral': [
                'okay', 'fine', 'normal', 'average', 'usual', 'regular', 'meh', 'whatever', 'idk', 'idc',
                'ğŸ˜', 'ğŸ˜‘', 'ğŸ˜¶', 'ğŸ˜¯', 'ğŸ˜¦', 'ğŸ˜§', 'ğŸ˜®', 'ğŸ˜²', 'ğŸ¤”', 'ğŸ¤­', 'ğŸ¤«', 'ğŸ¤¥', 'ğŸ˜¶', 'ğŸ˜', 'ğŸ˜‘', 'ğŸ˜¯', 'ğŸ˜¦', 'ğŸ˜§', 'ğŸ˜®', 'ğŸ˜²'
            ]
        }
        
        # è½¬æŠ˜è¯ï¼ˆæ–°å¢ï¼‰
        self.turnaround_words = {
            'ä½†æ˜¯', 'ä¸è¿‡', 'ç„¶è€Œ', 'å¯æ˜¯', 'åªæ˜¯', 'ä¸è¿‡', 'ä½†', 'yet', 'but', 'however',
            'although', 'though', 'even though', 'despite', 'in spite of', 'while',
            'è™½ç„¶', 'å°½ç®¡', 'å³ä½¿', 'å°±ç®—', 'å“ªæ€•', 'çºµç„¶', 'è™½è¯´', 'è™½è¯´å¦‚æ­¤',
            'lol', 'haha', 'ğŸ˜…', 'ğŸ˜Š', 'ğŸ˜‹', 'ğŸ˜„', 'ğŸ˜‚', 'ğŸ˜†', 'ğŸ˜‰', 'ğŸ˜'
        }
        
        # æƒ…æ„Ÿè½¬æŠ˜æ¨¡å¼ï¼ˆæ–°å¢ï¼‰
        self.turnaround_patterns = [
            r'ä½†æ˜¯.*?(å¼€å¿ƒ|å¿«ä¹|é«˜å…´|å¥½|æ£’|èµ|çˆ½|èˆ’æœ|è½»æ¾|æ”¾æ¾|è§£å†³|ä¿®å¤|æ²»æ„ˆ|fixed|solved|better|relief)',
            r'ä¸è¿‡.*?(å¼€å¿ƒ|å¿«ä¹|é«˜å…´|å¥½|æ£’|èµ|çˆ½|èˆ’æœ|è½»æ¾|æ”¾æ¾|è§£å†³|ä¿®å¤|æ²»æ„ˆ|fixed|solved|better|relief)',
            r'ç„¶è€Œ.*?(å¼€å¿ƒ|å¿«ä¹|é«˜å…´|å¥½|æ£’|èµ|çˆ½|èˆ’æœ|è½»æ¾|æ”¾æ¾|è§£å†³|ä¿®å¤|æ²»æ„ˆ|fixed|solved|better|relief)',
            r'but.*?(happy|good|great|amazing|wonderful|fantastic|fixed|solved|better|relief|cheered|helped)',
            r'however.*?(happy|good|great|amazing|wonderful|fantastic|fixed|solved|better|relief|cheered|helped)',
            r'yet.*?(happy|good|great|amazing|wonderful|fantastic|fixed|solved|better|relief|cheered|helped)',
            r'ğŸ˜©.*?(ğŸ˜Š|ğŸ˜‹|ğŸ˜„|ğŸ˜‚|ğŸ˜†|ğŸ˜‰|ğŸ˜)',
            r'ğŸ˜¢.*?(ğŸ˜Š|ğŸ˜‹|ğŸ˜„|ğŸ˜‚|ğŸ˜†|ğŸ˜‰|ğŸ˜)',
            r'ğŸ˜­.*?(ğŸ˜Š|ğŸ˜‹|ğŸ˜„|ğŸ˜‚|ğŸ˜†|ğŸ˜‰|ğŸ˜)',
            r'ğŸ˜”.*?(ğŸ˜Š|ğŸ˜‹|ğŸ˜„|ğŸ˜‚|ğŸ˜†|ğŸ˜‰|ğŸ˜)',
            r'ğŸ˜.*?(ğŸ˜Š|ğŸ˜‹|ğŸ˜„|ğŸ˜‚|ğŸ˜†|ğŸ˜‰|ğŸ˜)',
            r'ğŸ˜¤.*?(ğŸ˜Š|ğŸ˜‹|ğŸ˜„|ğŸ˜‚|ğŸ˜†|ğŸ˜‰|ğŸ˜)',
            r'ğŸ˜«.*?(ğŸ˜Š|ğŸ˜‹|ğŸ˜„|ğŸ˜‚|ğŸ˜†|ğŸ˜‰|ğŸ˜)',
            r'ğŸ˜©.*?(lol|haha|ğŸ˜…|ğŸ˜Š|ğŸ˜‹|ğŸ˜„|ğŸ˜‚|ğŸ˜†|ğŸ˜‰|ğŸ˜)',
            r'ğŸ˜¢.*?(lol|haha|ğŸ˜…|ğŸ˜Š|ğŸ˜‹|ğŸ˜„|ğŸ˜‚|ğŸ˜†|ğŸ˜‰|ğŸ˜)',
            r'ğŸ˜­.*?(lol|haha|ğŸ˜…|ğŸ˜Š|ğŸ˜‹|ğŸ˜„|ğŸ˜‚|ğŸ˜†|ğŸ˜‰|ğŸ˜)',
            r'ğŸ˜”.*?(lol|haha|ğŸ˜…|ğŸ˜Š|ğŸ˜‹|ğŸ˜„|ğŸ˜‚|ğŸ˜†|ğŸ˜‰|ğŸ˜)',
            r'ğŸ˜.*?(lol|haha|ğŸ˜…|ğŸ˜Š|ğŸ˜‹|ğŸ˜„|ğŸ˜‚|ğŸ˜†|ğŸ˜‰|ğŸ˜)',
            r'ğŸ˜¤.*?(lol|haha|ğŸ˜…|ğŸ˜Š|ğŸ˜‹|ğŸ˜„|ğŸ˜‚|ğŸ˜†|ğŸ˜‰|ğŸ˜)',
            r'ğŸ˜«.*?(lol|haha|ğŸ˜…|ğŸ˜Š|ğŸ˜‹|ğŸ˜„|ğŸ˜‚|ğŸ˜†|ğŸ˜‰|ğŸ˜)'
        ]
        
        # æ ‡ç‚¹ç¬¦å·æ¨¡å¼
        self.punctuation_patterns = {
            'exclamation': r'!+',
            'question': r'\?+',
            'ellipsis': r'\.{3,}',
            'caps_words': r'\b[A-Z]{2,}\b'
        }
        
        # ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
        self.compiled_patterns = {k: re.compile(v) for k, v in self.punctuation_patterns.items()}
        self.compiled_turnaround_patterns = [re.compile(pattern, re.IGNORECASE) for pattern in self.turnaround_patterns]
    
    def extract_linguistic_features(self, text: str) -> Dict[str, float]:
        """
        æå–è¯­è¨€å­¦ç‰¹å¾
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            è¯­è¨€å­¦ç‰¹å¾å­—å…¸
        """
        features = {}
        
        # åŸºæœ¬ç»Ÿè®¡ç‰¹å¾
        features['text_length'] = len(text)
        features['word_count'] = len(text.split())
        features['char_count'] = len(text)
        features['avg_word_length'] = np.mean([len(word) for word in text.split()]) if text.split() else 0
        features['sentence_count'] = len(re.split(r'[.!?]+', text))
        features['avg_sentence_length'] = features['word_count'] / features['sentence_count'] if features['sentence_count'] > 0 else 0
        
        # è¯æ±‡å¤šæ ·æ€§
        words = text.lower().split()
        if words:
            features['unique_words'] = len(set(words))
            features['lexical_diversity'] = features['unique_words'] / features['word_count']
            features['type_token_ratio'] = features['unique_words'] / features['word_count']
        else:
            features['unique_words'] = 0
            features['lexical_diversity'] = 0
            features['type_token_ratio'] = 0
        
        # æ ‡ç‚¹ç¬¦å·ç‰¹å¾
        features['exclamation_count'] = len(self.compiled_patterns['exclamation'].findall(text))
        features['question_count'] = len(self.compiled_patterns['question'].findall(text))
        features['ellipsis_count'] = len(self.compiled_patterns['ellipsis'].findall(text))
        features['caps_words_count'] = len(self.compiled_patterns['caps_words'].findall(text))
        
        # å¤§å†™å­—æ¯æ¯”ä¾‹
        features['uppercase_ratio'] = sum(1 for c in text if c.isupper()) / len(text) if text else 0
        
        return features
    
    def extract_depression_features(self, text: str) -> Dict[str, float]:
        """
        æå–æŠ‘éƒç›¸å…³ç‰¹å¾
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            æŠ‘éƒç›¸å…³ç‰¹å¾å­—å…¸
        """
        features = {}
        text_lower = text.lower()
        
        # è®¡ç®—å„ç±»æŠ‘éƒå…³é”®è¯çš„å‡ºç°æ¬¡æ•°ï¼ˆæ”¹è¿›åŒ¹é…æ–¹æ³•ï¼‰
        for category, keywords in self.depression_keywords.items():
            count = 0
            for keyword in keywords:
                # å¯¹äºçŸ­è¯­ï¼Œä½¿ç”¨æ›´çµæ´»çš„åŒ¹é…
                if ' ' in keyword:
                    # çŸ­è¯­åŒ¹é…ï¼Œå…è®¸éƒ¨åˆ†åŒ¹é…
                    if keyword in text_lower:
                        count += 1
                else:
                    # å•è¯åŒ¹é…ï¼Œä½¿ç”¨å•è¯è¾¹ç•Œ
                    pattern = r'\b' + re.escape(keyword) + r'\b'
                    count += len(re.findall(pattern, text_lower))
            features[f'depression_{category}_count'] = count
        
        # æ€»æŠ‘éƒå…³é”®è¯æ•°é‡
        total_count = 0
        for category, keywords in self.depression_keywords.items():
            for keyword in keywords:
                if ' ' in keyword:
                    if keyword in text_lower:
                        total_count += 1
                else:
                    pattern = r'\b' + re.escape(keyword) + r'\b'
                    total_count += len(re.findall(pattern, text_lower))
        
        features['total_depression_words'] = total_count
        
        # æŠ‘éƒè¯æ±‡å¯†åº¦
        word_count = len(text.split())
        features['depression_word_density'] = total_count / word_count if word_count > 0 else 0
        
        # æŠ‘éƒè¯æ±‡ç±»åˆ«æ•°
        features['depression_categories'] = sum(1 for category, keywords in self.depression_keywords.items() 
                                              if features[f'depression_{category}_count'] > 0)
        
        return features
    
    def extract_emotion_features(self, text: str) -> Dict[str, float]:
        """
        æå–æƒ…æ„Ÿç‰¹å¾
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            æƒ…æ„Ÿç‰¹å¾å­—å…¸
        """
        features = {}
        text_lower = text.lower()
        
        # è®¡ç®—å„ç±»æƒ…æ„Ÿè¯æ±‡çš„å‡ºç°æ¬¡æ•°
        for emotion, words in self.emotion_words.items():
            count = sum(text_lower.count(word) for word in words)
            features[f'{emotion}_emotion_count'] = count
        
        # æƒ…æ„Ÿè¯æ±‡æ€»æ•°
        all_emotion_words = [word for words in self.emotion_words.values() for word in words]
        features['total_emotion_words'] = sum(text_lower.count(word) for word in all_emotion_words)
        
        # æƒ…æ„Ÿè¯æ±‡å¯†åº¦
        word_count = len(text.split())
        features['emotion_word_density'] = features['total_emotion_words'] / word_count if word_count > 0 else 0
        
        # æƒ…æ„Ÿææ€§
        positive_count = features['positive_emotion_count']
        negative_count = features['negative_emotion_count']
        total_emotion = positive_count + negative_count
        
        if total_emotion > 0:
            features['emotion_polarity'] = (positive_count - negative_count) / total_emotion
        else:
            features['emotion_polarity'] = 0
        
        return features
    
    def extract_social_media_features(self, text: str) -> Dict[str, float]:
        """
        æå–ç¤¾äº¤åª’ä½“ç‰¹å®šç‰¹å¾
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            ç¤¾äº¤åª’ä½“ç‰¹å¾å­—å…¸
        """
        features = {}
        
        # ç¤¾äº¤åª’ä½“æ ‡è®°
        features['hashtag_count'] = len(re.findall(r'#\w+', text))
        features['mention_count'] = len(re.findall(r'@\w+', text))
        features['url_count'] = len(re.findall(r'http[s]?://\S+', text))
        features['emoticon_count'] = len(re.findall(r'[:;=]-?[)(/|\\pPoO]', text))
        
        # é‡å¤å­—ç¬¦å’Œå•è¯
        features['repeated_char_count'] = len(re.findall(r'(.)\1{2,}', text))
        features['repeated_word_count'] = len(re.findall(r'\b(\w+)(\s+\1){2,}\b', text))
        
        # æ„Ÿå¹å·å’Œé—®å·çš„ä½¿ç”¨
        features['exclamation_density'] = text.count('!') / len(text) if text else 0
        features['question_density'] = text.count('?') / len(text) if text else 0
        
        return features
    
    def extract_all_features(self, text: str) -> Dict[str, float]:
        """
        æå–æ‰€æœ‰ç‰¹å¾
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            æ‰€æœ‰ç‰¹å¾çš„å­—å…¸
        """
        features = {}
        
        try:
            # åˆå¹¶æ‰€æœ‰ç‰¹å¾
            features.update(self.extract_linguistic_features(text))
            features.update(self.extract_depression_features(text))
            features.update(self.extract_emotion_features(text))
            features.update(self.extract_social_media_features(text))
            # æ·»åŠ æƒ…æ„Ÿè½¬æŠ˜ç‰¹å¾ï¼ˆæ–°å¢ï¼‰
            features.update(self.extract_turnaround_features(text))
        except Exception as e:
            logger.error(f"ç‰¹å¾æå–å¤±è´¥: {e}")
            # è¿”å›é»˜è®¤ç‰¹å¾
            features = self._get_default_features()
        
        return features
    
    def _get_default_features(self) -> Dict[str, float]:
        """
        è·å–é»˜è®¤ç‰¹å¾ï¼ˆå½“ç‰¹å¾æå–å¤±è´¥æ—¶ä½¿ç”¨ï¼‰
        
        Returns:
            é»˜è®¤ç‰¹å¾å­—å…¸
        """
        # è·å–æ‰€æœ‰ç‰¹å¾åç§°
        sample_text = "This is a sample text for feature extraction."
        try:
            default_features = self.extract_linguistic_features(sample_text)
            default_features.update(self.extract_depression_features(sample_text))
            default_features.update(self.extract_emotion_features(sample_text))
            default_features.update(self.extract_social_media_features(sample_text))
            default_features.update(self.extract_turnaround_features(sample_text))
            # å°†æ‰€æœ‰å€¼è®¾ä¸º0
            return {k: 0.0 for k in default_features.keys()}
        except:
            # å¦‚æœè¿é»˜è®¤ç‰¹å¾éƒ½è·å–å¤±è´¥ï¼Œè¿”å›åŸºæœ¬ç‰¹å¾
            return {
                'text_length': 0.0, 'word_count': 0.0, 'char_count': 0.0,
                'avg_word_length': 0.0, 'sentence_count': 0.0, 'avg_sentence_length': 0.0,
                'unique_words': 0.0, 'lexical_diversity': 0.0, 'type_token_ratio': 0.0,
                'exclamation_count': 0.0, 'question_count': 0.0, 'ellipsis_count': 0.0,
                'caps_words_count': 0.0, 'uppercase_ratio': 0.0
            }
    
    def extract_batch_features(self, texts: List[str]) -> List[Dict[str, float]]:
        """
        æ‰¹é‡æå–ç‰¹å¾
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            ç‰¹å¾å­—å…¸åˆ—è¡¨
        """
        if not texts:
            return []
        
        # è·å–æ ‡å‡†ç‰¹å¾åç§°
        standard_features = self._get_default_features()
        feature_names = list(standard_features.keys())
        
        features_list = []
        for text in texts:
            try:
                features = self.extract_all_features(text)
                # ç¡®ä¿æ‰€æœ‰ç‰¹å¾éƒ½å­˜åœ¨
                for name in feature_names:
                    if name not in features:
                        features[name] = 0.0
                features_list.append(features)
            except Exception as e:
                logger.warning(f"ç‰¹å¾æå–å¤±è´¥: {e}")
                # è¿”å›é»˜è®¤ç‰¹å¾å­—å…¸
                features_list.append(standard_features.copy())
        
        return features_list
    
    def get_feature_names(self) -> List[str]:
        """
        è·å–æ‰€æœ‰ç‰¹å¾åç§°
        
        Returns:
            ç‰¹å¾åç§°åˆ—è¡¨
        """
        # ä½¿ç”¨ç¤ºä¾‹æ–‡æœ¬è·å–ç‰¹å¾åç§°
        sample_text = "This is a sample text for feature extraction."
        features = self.extract_all_features(sample_text)
        return list(features.keys())
    
    def features_to_array(self, features_list: List[Dict[str, float]]) -> np.ndarray:
        """
        å°†ç‰¹å¾å­—å…¸åˆ—è¡¨è½¬æ¢ä¸ºnumpyæ•°ç»„
        
        Args:
            features_list: ç‰¹å¾å­—å…¸åˆ—è¡¨
            
        Returns:
            numpyæ•°ç»„
        """
        if not features_list:
            return np.array([])
        
        # è·å–æ‰€æœ‰ç‰¹å¾åç§°
        feature_names = list(features_list[0].keys())
        
        # è½¬æ¢ä¸ºæ•°ç»„
        array = np.array([[features.get(name, 0.0) for name in feature_names] 
                         for features in features_list])
        
        return array
    
    def extract_turnaround_features(self, text: str) -> Dict[str, float]:
        """
        æå–æƒ…æ„Ÿè½¬æŠ˜ç‰¹å¾ï¼ˆæ–°å¢ï¼‰
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            æƒ…æ„Ÿè½¬æŠ˜ç‰¹å¾å­—å…¸
        """
        features = {}
        text_lower = text.lower()
        
        # è½¬æŠ˜è¯è®¡æ•°
        turnaround_count = 0
        for word in self.turnaround_words:
            if word in text_lower:
                turnaround_count += 1
        features['turnaround_word_count'] = turnaround_count
        
        # è½¬æŠ˜æ¨¡å¼åŒ¹é…
        pattern_matches = 0
        for pattern in self.compiled_turnaround_patterns:
            if pattern.search(text_lower):
                pattern_matches += 1
        features['turnaround_pattern_count'] = pattern_matches
        
        # è½¬æŠ˜å¼ºåº¦ï¼ˆè½¬æŠ˜è¯æ•°é‡ / æ€»è¯æ•°ï¼‰
        total_words = len(text.split())
        if total_words > 0:
            features['turnaround_intensity'] = turnaround_count / total_words
        else:
            features['turnaround_intensity'] = 0.0
        
        # æƒ…æ„Ÿå˜åŒ–åˆ†æ
        sentences = re.split(r'[.!?ã€‚ï¼ï¼Ÿ]', text)
        features['sentence_count'] = len([s for s in sentences if s.strip()])
        
        # åˆ†æç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªå¥å­çš„æƒ…æ„Ÿ
        negative_first = 0
        positive_first = 0
        negative_last = 0
        positive_last = 0
        
        if sentences:
            first_sentence = sentences[0].lower()
            last_sentence = sentences[-1].lower()
            
            # ç¬¬ä¸€ä¸ªå¥å­çš„æƒ…æ„Ÿ
            for word in self.emotion_words['negative']:
                if word in first_sentence:
                    negative_first += 1
            for word in self.emotion_words['positive']:
                if word in first_sentence:
                    positive_first += 1
            
            # æœ€åä¸€ä¸ªå¥å­çš„æƒ…æ„Ÿ
            for word in self.emotion_words['negative']:
                if word in last_sentence:
                    negative_last += 1
            for word in self.emotion_words['positive']:
                if word in last_sentence:
                    positive_last += 1
        
        features['negative_first_sentence'] = negative_first
        features['positive_first_sentence'] = positive_first
        features['negative_last_sentence'] = negative_last
        features['positive_last_sentence'] = positive_last
        
        # æƒ…æ„Ÿå˜åŒ–æ–¹å‘
        if negative_first > positive_first and positive_last > negative_last:
            features['sentiment_turnaround'] = 1.0  # è´Ÿé¢è½¬æ­£é¢
        elif positive_first > negative_first and negative_last > positive_last:
            features['sentiment_turnaround'] = -1.0  # æ­£é¢è½¬è´Ÿé¢
        else:
            features['sentiment_turnaround'] = 0.0  # æ— å˜åŒ–æˆ–åŒå‘
        
        # æ•´ä½“æƒ…æ„Ÿå€¾å‘ï¼ˆè€ƒè™‘è½¬æŠ˜ï¼‰
        negative_count = sum(1 for word in self.emotion_words['negative'] if word in text_lower)
        positive_count = sum(1 for word in self.emotion_words['positive'] if word in text_lower)
        
        if negative_count + positive_count > 0:
            base_sentiment = (positive_count - negative_count) / (negative_count + positive_count)
            
            # å¦‚æœæœ‰è½¬æŠ˜è¯ï¼Œè°ƒæ•´æƒ…æ„Ÿåˆ†æ•°
            if turnaround_count > 0:
                # è½¬æŠ˜è¯è¶Šå¤šï¼Œæƒ…æ„Ÿè¶Šåå‘ä¸­æ€§æˆ–æ­£é¢
                adjustment = min(turnaround_count * 0.2, 0.5)  # æœ€å¤šè°ƒæ•´0.5
                adjusted_sentiment = base_sentiment + adjustment
                features['overall_sentiment'] = max(-1.0, min(1.0, adjusted_sentiment))
            else:
                features['overall_sentiment'] = base_sentiment
        else:
            features['overall_sentiment'] = 0.0
        
        return features
