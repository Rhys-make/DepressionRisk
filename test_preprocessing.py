#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®é¢„å¤„ç†åŠŸèƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•æ–‡æœ¬æ¸…æ´—ã€ç‰¹å¾æå–ã€æ•°æ®æ ‡å‡†åŒ–ç­‰åŠŸèƒ½
"""

import sys
import os
import pandas as pd
import numpy as np
import logging
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from data_processing.preprocessor import DataProcessor
from data_processing.text_cleaner import TextCleaner
from data_processing.feature_extractor import FeatureExtractor

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_text_cleaner():
    """æµ‹è¯•æ–‡æœ¬æ¸…æ´—åŠŸèƒ½"""
    print("ğŸ§¹ æµ‹è¯•æ–‡æœ¬æ¸…æ´—åŠŸèƒ½")
    print("=" * 50)
    
    cleaner = TextCleaner()
    
    # æµ‹è¯•ç”¨ä¾‹
    test_texts = [
        "I am so happy today!!! ğŸ˜Š #blessed @friend",
        "I feel so sad and hopeless... :( #depression",
        "RT @user: This is a retweet with http://example.com",
        "I can't sleep at night... my mind keeps racing...",
        "Had a great day with friends! Everything is wonderful! :D",
        "Sometimes I think about hurting myself...",
        "I'm feeling blessed and thankful for everything! ğŸ™",
        "I feel worthless and like a complete failure in life...",
        "Just finished a challenging project! Feeling accomplished!",
        "I want to disappear and never be seen again..."
    ]
    
    print("åŸå§‹æ–‡æœ¬ -> æ¸…æ´—åæ–‡æœ¬:")
    print("-" * 80)
    
    for i, text in enumerate(test_texts, 1):
        cleaned = cleaner.clean_text(text)
        print(f"{i:2d}. {text[:60]:<60} -> {cleaned[:60]:<60}")
    
    print()

def test_feature_extractor():
    """æµ‹è¯•ç‰¹å¾æå–åŠŸèƒ½"""
    print("ğŸ” æµ‹è¯•ç‰¹å¾æå–åŠŸèƒ½")
    print("=" * 50)
    
    extractor = FeatureExtractor()
    
    # æµ‹è¯•ç”¨ä¾‹
    test_texts = [
        "I am so happy today! Everything feels wonderful!",
        "I am so sad today! I feel completely hopeless and worthless.",
        "I can't sleep at night. My mind keeps racing with suicidal thoughts.",
        "I love my life and everything in it!",
        "I think about death a lot and can't stop these suicidal thoughts."
    ]
    
    for i, text in enumerate(test_texts, 1):
        print(f"\nğŸ“ æµ‹è¯•æ–‡æœ¬ {i}: {text}")
        print("-" * 60)
        
        # æå–æ‰€æœ‰ç‰¹å¾
        features = extractor.extract_all_features(text)
        
        # æ˜¾ç¤ºå…³é”®ç‰¹å¾
        key_categories = [
            ('è¯­è¨€å­¦ç‰¹å¾', ['text_length', 'word_count', 'avg_word_length']),
            ('æŠ‘éƒç‰¹å¾', [f for f in features.keys() if 'depression' in f]),
            ('æƒ…æ„Ÿç‰¹å¾', [f for f in features.keys() if 'emotion' in f]),
            ('æ ‡ç‚¹ç‰¹å¾', ['exclamation_count', 'question_count', 'ellipsis_count'])
        ]
        
        for category, feature_list in key_categories:
            print(f"\n{category}:")
            for feature in feature_list[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                if feature in features:
                    print(f"  {feature}: {features[feature]}")

def test_data_processor():
    """æµ‹è¯•æ•°æ®å¤„ç†å™¨åŠŸèƒ½"""
    print("\nâš™ï¸  æµ‹è¯•æ•°æ®å¤„ç†å™¨åŠŸèƒ½")
    print("=" * 50)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = pd.DataFrame({
        'text': [
            "I am so happy today! Everything feels wonderful!",
            "I am so sad today! I feel completely hopeless.",
            "I can't sleep at night. My mind keeps racing.",
            "I love my life and everything in it!",
            "I think about death a lot and can't stop these thoughts.",
            "I'm feeling blessed and thankful for everything!",
            "I feel worthless and like a complete failure.",
            "Just finished a challenging project! Feeling accomplished!",
            "I want to disappear and never be seen again.",
            "I'm excited about the future and all possibilities!"
        ],
        'label': [0, 1, 1, 0, 1, 0, 1, 0, 1, 0]  # 0=ä½é£é™©, 1=é«˜é£é™©
    })
    
    print(f"ğŸ“Š åŸå§‹æ•°æ®: {len(test_data)} è¡Œ")
    print(f"æ ‡ç­¾åˆ†å¸ƒ: {test_data['label'].value_counts().to_dict()}")
    
    # åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨
    processor = DataProcessor(
        text_column='text',
        label_column='label',
        min_text_length=1,
        max_text_length=500
    )
    
    # å¤„ç†æ•°æ®
    print("\nğŸ”„ å¼€å§‹æ•°æ®å¤„ç†...")
    processed_data = processor.process_social_media_data(test_data)
    
    print(f"âœ… å¤„ç†å®Œæˆ: {len(processed_data)} è¡Œ")
    print(f"ğŸ“ˆ ç‰¹å¾æ•°é‡: {len(processor.feature_names)}")
    
    # æ˜¾ç¤ºç‰¹å¾åç§°
    print(f"\nğŸ“‹ ç‰¹å¾åˆ—è¡¨ (å‰10ä¸ª):")
    for i, feature in enumerate(processor.feature_names[:10]):
        print(f"  {i+1:2d}. {feature}")
    
    if len(processor.feature_names) > 10:
        print(f"  ... è¿˜æœ‰ {len(processor.feature_names) - 10} ä¸ªç‰¹å¾")

def test_feature_preparation():
    """æµ‹è¯•ç‰¹å¾å‡†å¤‡åŠŸèƒ½"""
    print("\nğŸ¯ æµ‹è¯•ç‰¹å¾å‡†å¤‡åŠŸèƒ½")
    print("=" * 50)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = pd.DataFrame({
        'text': [
            "I am so happy today! Everything feels wonderful!",
            "I am so sad today! I feel completely hopeless.",
            "I can't sleep at night. My mind keeps racing.",
            "I love my life and everything in it!",
            "I think about death a lot and can't stop these thoughts."
        ],
        'label': [0, 1, 1, 0, 1]
    })
    
    # åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨
    processor = DataProcessor(
        text_column='text',
        label_column='label',
        min_text_length=1,
        max_text_length=500
    )
    
    # å¤„ç†æ•°æ®
    processed_data = processor.process_social_media_data(test_data)
    
    # å‡†å¤‡ç‰¹å¾
    print("ğŸ”„ å‡†å¤‡è®­ç»ƒç‰¹å¾...")
    X_train, y_train = processor.prepare_features(processed_data, label_column='label', fit_scaler=True)
    
    print(f"âœ… ç‰¹å¾å‡†å¤‡å®Œæˆ:")
    print(f"  - ç‰¹å¾çŸ©é˜µå½¢çŠ¶: {X_train.shape}")
    print(f"  - æ ‡ç­¾å‘é‡å½¢çŠ¶: {y_train.shape}")
    print(f"  - æ ‡ç­¾åˆ†å¸ƒ: {np.bincount(y_train)}")
    
    # æµ‹è¯•é¢„æµ‹æ—¶çš„ç‰¹å¾å‡†å¤‡
    print("\nğŸ”„ æµ‹è¯•é¢„æµ‹ç‰¹å¾å‡†å¤‡...")
    test_text = "I feel sad and hopeless today"
    test_df = pd.DataFrame({'text': [test_text]})
    test_processed = processor.process_social_media_data(test_df)
    X_test, _ = processor.prepare_features(test_processed, fit_scaler=False)
    
    print(f"âœ… é¢„æµ‹ç‰¹å¾å‡†å¤‡å®Œæˆ:")
    print(f"  - æµ‹è¯•ç‰¹å¾å½¢çŠ¶: {X_test.shape}")
    print(f"  - ç‰¹å¾ç»´åº¦åŒ¹é…: {'âœ…' if X_test.shape[1] == X_train.shape[1] else 'âŒ'}")

def test_data_persistence():
    """æµ‹è¯•æ•°æ®æŒä¹…åŒ–åŠŸèƒ½"""
    print("\nğŸ’¾ æµ‹è¯•æ•°æ®æŒä¹…åŒ–åŠŸèƒ½")
    print("=" * 50)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = pd.DataFrame({
        'text': [
            "I am so happy today! Everything feels wonderful!",
            "I am so sad today! I feel completely hopeless.",
            "I can't sleep at night. My mind keeps racing.",
            "I love my life and everything in it!",
            "I think about death a lot and can't stop these thoughts."
        ],
        'label': [0, 1, 1, 0, 1]
    })
    
    # åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨
    processor = DataProcessor(
        text_column='text',
        label_column='label',
        min_text_length=1,
        max_text_length=500
    )
    
    # å¤„ç†æ•°æ®
    processed_data = processor.process_social_media_data(test_data)
    X_train, y_train = processor.prepare_features(processed_data, label_column='label', fit_scaler=True)
    
    # ä¿å­˜å¤„ç†å™¨
    save_path = Path("test_processor.pkl")
    print(f"ğŸ’¾ ä¿å­˜å¤„ç†å™¨åˆ°: {save_path}")
    processor.save_processor(save_path)
    
    # åŠ è½½å¤„ç†å™¨
    print(f"ğŸ“‚ åŠ è½½å¤„ç†å™¨ä»: {save_path}")
    new_processor = DataProcessor()
    new_processor.load_processor(save_path)
    
    # éªŒè¯åŠ è½½çš„å¤„ç†å™¨
    print("âœ… éªŒè¯åŠ è½½çš„å¤„ç†å™¨:")
    print(f"  - ç‰¹å¾åç§°æ•°é‡: {len(new_processor.feature_names)}")
    print(f"  - ç‰¹å¾åç§°åŒ¹é…: {'âœ…' if new_processor.feature_names == processor.feature_names else 'âŒ'}")
    
    # æµ‹è¯•ä½¿ç”¨åŠ è½½çš„å¤„ç†å™¨
    test_text = "I feel sad and hopeless today"
    test_df = pd.DataFrame({'text': [test_text]})
    test_processed = new_processor.process_social_media_data(test_df)
    X_test, _ = new_processor.prepare_features(test_processed, fit_scaler=False)
    
    print(f"  - é¢„æµ‹ç‰¹å¾å½¢çŠ¶: {X_test.shape}")
    print(f"  - ç‰¹å¾ç»´åº¦åŒ¹é…: {'âœ…' if X_test.shape[1] == X_train.shape[1] else 'âŒ'}")
    
    # æ¸…ç†æµ‹è¯•æ–‡ä»¶
    if save_path.exists():
        save_path.unlink()
        print(f"ğŸ—‘ï¸  æ¸…ç†æµ‹è¯•æ–‡ä»¶: {save_path}")

def test_error_handling():
    """æµ‹è¯•é”™è¯¯å¤„ç†åŠŸèƒ½"""
    print("\nâš ï¸  æµ‹è¯•é”™è¯¯å¤„ç†åŠŸèƒ½")
    print("=" * 50)
    
    processor = DataProcessor(
        text_column='text',
        label_column='label',
        min_text_length=1,
        max_text_length=500
    )
    
    # æµ‹è¯•ç©ºæ–‡æœ¬
    print("ğŸ“ æµ‹è¯•ç©ºæ–‡æœ¬å¤„ç†:")
    empty_data = pd.DataFrame({
        'text': ['', '   ', 'I am happy', ''],
        'label': [0, 1, 0, 1]
    })
    
    try:
        processed = processor.process_social_media_data(empty_data)
        print(f"  âœ… ç©ºæ–‡æœ¬å¤„ç†æˆåŠŸ: {len(processed)} è¡Œ")
    except Exception as e:
        print(f"  âŒ ç©ºæ–‡æœ¬å¤„ç†å¤±è´¥: {e}")
    
    # æµ‹è¯•ç¼ºå¤±æ ‡ç­¾
    print("\nğŸ“ æµ‹è¯•ç¼ºå¤±æ ‡ç­¾å¤„ç†:")
    missing_label_data = pd.DataFrame({
        'text': ['I am happy', 'I am sad', 'I am okay'],
        'label': [0, np.nan, 1]
    })
    
    try:
        processed = processor.process_social_media_data(missing_label_data)
        print(f"  âœ… ç¼ºå¤±æ ‡ç­¾å¤„ç†æˆåŠŸ: {len(processed)} è¡Œ")
    except Exception as e:
        print(f"  âŒ ç¼ºå¤±æ ‡ç­¾å¤„ç†å¤±è´¥: {e}")
    
    # æµ‹è¯•è¶…é•¿æ–‡æœ¬
    print("\nğŸ“ æµ‹è¯•è¶…é•¿æ–‡æœ¬å¤„ç†:")
    long_text = "I am " + "very " * 1000 + "happy!"
    long_data = pd.DataFrame({
        'text': [long_text],
        'label': [0]
    })
    
    try:
        processed = processor.process_social_media_data(long_data)
        print(f"  âœ… è¶…é•¿æ–‡æœ¬å¤„ç†æˆåŠŸ: {len(processed)} è¡Œ")
    except Exception as e:
        print(f"  âŒ è¶…é•¿æ–‡æœ¬å¤„ç†å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æ•°æ®é¢„å¤„ç†åŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    
    try:
        # 1. æµ‹è¯•æ–‡æœ¬æ¸…æ´—
        test_text_cleaner()
        
        # 2. æµ‹è¯•ç‰¹å¾æå–
        test_feature_extractor()
        
        # 3. æµ‹è¯•æ•°æ®å¤„ç†å™¨
        test_data_processor()
        
        # 4. æµ‹è¯•ç‰¹å¾å‡†å¤‡
        test_feature_preparation()
        
        # 5. æµ‹è¯•æ•°æ®æŒä¹…åŒ–
        test_data_persistence()
        
        # 6. æµ‹è¯•é”™è¯¯å¤„ç†
        test_error_handling()
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        print("âœ… æ•°æ®é¢„å¤„ç†åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}", exc_info=True)

if __name__ == "__main__":
    main()
