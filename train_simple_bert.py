#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€åŒ–ç‰ˆBERTæ¨¡å‹è®­ç»ƒè„šæœ¬ï¼ˆCPUå‹å¥½ï¼‰
ä¸“ä¸ºCPUè®­ç»ƒä¼˜åŒ–çš„è½»é‡ç‰ˆæœ¬
"""

import sys
import os
import logging
import random
import numpy as np
import pandas as pd
from pathlib import Path

# åˆ›å»ºæ—¥å¿—ç›®å½•
log_dir = Path('logs')
log_dir.mkdir(exist_ok=True)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_dir / 'simple_training.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# è®¾ç½®éšæœºç§å­
SEED = 42
random.seed(SEED)
np.random.seed(SEED)

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from data_processing.preprocessor import DataProcessor
from models.model_factory import ModelFactory


def create_simple_bert_model():
    """åˆ›å»ºç®€åŒ–çš„BERTæ¨¡å‹ï¼ˆCPUå‹å¥½ï¼‰"""
    logger.info("åˆ›å»ºç®€åŒ–BERTæ¨¡å‹...")
    
    try:
        # éå¸¸è½»é‡çš„é…ç½®
        model_params = {
            'symptom_capsules': 4,        # å‡å°‘åˆ°4ä¸ªèƒ¶å›Š
            'capsule_dim': 8,             # å‡å°‘èƒ¶å›Šç»´åº¦
            'max_length': 64,             # å¤§å¹…å‡å°‘åºåˆ—é•¿åº¦
            'dropout': 0.1,               # å‡å°‘dropout
            'num_iterations': 3           # å‡å°‘è·¯ç”±è¿­ä»£
        }
        
        model = ModelFactory.create_model(
            model_type='bert_capsule',
            bert_model_name='distilbert-base-uncased',  # ä½¿ç”¨DistilBERTï¼ˆæ›´å°æ›´å¿«ï¼‰
            **model_params
        )
        
        # ä¿å­˜æ¨¡å‹å‚æ•°åˆ°æ¨¡å‹å¯¹è±¡ä¸­
        model.model_params = model_params
        model.bert_model_name = 'distilbert-base-uncased'
        
        logger.info("âœ… æˆåŠŸåˆ›å»ºç®€åŒ–BERTæ¨¡å‹")
        return model
    except Exception as e:
        logger.error(f"âŒ åˆ›å»ºæ¨¡å‹å¤±è´¥: {e}")
        return None


def load_sample_data():
    """åŠ è½½å°‘é‡æ ·æœ¬æ•°æ®è¿›è¡Œå¿«é€Ÿæµ‹è¯•"""
    logger.info("åŠ è½½æ ·æœ¬æ•°æ®...")
    
    # åˆ›å»ºå°‘é‡ç¤ºä¾‹æ•°æ®
    sample_texts = [
        "I feel so sad and hopeless today",
        "Had a great day with friends",
        "I can't sleep at night",
        "Feeling really happy today",
        "I feel like a burden",
        "Today was productive",
        "Everything feels meaningless",
        "Just had an amazing day",
        "I feel so alone",
        "Life is beautiful"
    ] * 5  # é‡å¤5æ¬¡å¾—åˆ°50ä¸ªæ ·æœ¬
    
    labels = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0] * 5
    
    data = pd.DataFrame({
        'text': sample_texts,
        'label': labels
    })
    
    # ç®€å•åˆ†å‰²
    train_data = data[:30]  # 30ä¸ªè®­ç»ƒæ ·æœ¬
    val_data = data[30:40]   # 10ä¸ªéªŒè¯æ ·æœ¬
    test_data = data[40:]    # 10ä¸ªæµ‹è¯•æ ·æœ¬
    
    return {
        'train_texts': train_data['text'].tolist(),
        'val_texts': val_data['text'].tolist(),
        'test_texts': test_data['text'].tolist(),
        'y_train': train_data['label'].values,
        'y_val': val_data['label'].values,
        'y_test': test_data['label'].values
    }


def load_real_data():
    """åŠ è½½çœŸå®æ•°æ®é›†"""
    logger.info("åŠ è½½çœŸå®æ•°æ®é›†...")
    
    try:
        # å°è¯•åŠ è½½çœŸå®æ•°æ®é›†
        data_path = Path('data/raw/simple_sample_data_5000.csv')
        if data_path.exists():
            logger.info(f"ğŸ“ æ‰¾åˆ°æ•°æ®é›†: {data_path}")
            data = pd.read_csv(data_path)
            logger.info(f"ğŸ“Š æ•°æ®é›†ä¿¡æ¯: {len(data)} è¡Œ, åˆ—: {list(data.columns)}")
            
            # æ£€æŸ¥å¿…è¦çš„åˆ—
            if 'text' not in data.columns or 'label' not in data.columns:
                logger.error("âŒ æ•°æ®é›†ç¼ºå°‘å¿…è¦çš„åˆ—: text æˆ– label")
                return None
            
            # æ•°æ®é¢„å¤„ç†
            processor = DataProcessor()
            processed_data = processor.process_social_media_data(data)
            
            logger.info(f"âœ… æ•°æ®é¢„å¤„ç†å®Œæˆ: {len(processed_data)} è¡Œ")
            
            # åˆ†å‰²æ•°æ®
            from sklearn.model_selection import train_test_split
            
            # é¦–å…ˆåˆ†å‰²å‡ºæµ‹è¯•é›†
            train_val_data, test_data = train_test_split(
                processed_data, 
                test_size=0.2, 
                random_state=42, 
                stratify=processed_data['label']
            )
            
            # ç„¶ååˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†
            train_data, val_data = train_test_split(
                train_val_data, 
                test_size=0.2, 
                random_state=42, 
                stratify=train_val_data['label']
            )
            
            logger.info(f"ğŸ“Š æ•°æ®åˆ†å‰²å®Œæˆ:")
            logger.info(f"  è®­ç»ƒé›†: {len(train_data)} è¡Œ")
            logger.info(f"  éªŒè¯é›†: {len(val_data)} è¡Œ") 
            logger.info(f"  æµ‹è¯•é›†: {len(test_data)} è¡Œ")
            
            # æ£€æŸ¥æ ‡ç­¾åˆ†å¸ƒ
            logger.info("ğŸ“ˆ æ ‡ç­¾åˆ†å¸ƒ:")
            logger.info(f"  è®­ç»ƒé›†: {train_data['label'].value_counts().to_dict()}")
            logger.info(f"  éªŒè¯é›†: {val_data['label'].value_counts().to_dict()}")
            logger.info(f"  æµ‹è¯•é›†: {test_data['label'].value_counts().to_dict()}")
            
            return {
                'train_texts': train_data['text'].tolist(),
                'val_texts': val_data['text'].tolist(),
                'test_texts': test_data['text'].tolist(),
                'y_train': train_data['label'].values,
                'y_val': val_data['label'].values,
                'y_test': test_data['label'].values
            }
        else:
            logger.warning("âš ï¸ æœªæ‰¾åˆ°çœŸå®æ•°æ®é›†ï¼Œä½¿ç”¨ç¤ºä¾‹æ•°æ®")
            return load_sample_data()
            
    except Exception as e:
        logger.error(f"âŒ åŠ è½½çœŸå®æ•°æ®é›†å¤±è´¥: {e}")
        logger.warning("âš ï¸ å›é€€åˆ°ç¤ºä¾‹æ•°æ®")
        return load_sample_data()


def train_simple_model():
    """è®­ç»ƒç®€åŒ–æ¨¡å‹"""
    logger.info("ğŸš€ å¼€å§‹ç®€åŒ–BERTæ¨¡å‹è®­ç»ƒ...")
    
    # 1. åˆ›å»ºæ¨¡å‹
    model = create_simple_bert_model()
    if model is None:
        logger.error("âŒ æ— æ³•åˆ›å»ºæ¨¡å‹")
        return False
    
    # 2. åŠ è½½æ•°æ®
    data = load_real_data() # Changed to load_real_data
    logger.info(f"ğŸ“Š æ•°æ®åŠ è½½å®Œæˆ: è®­ç»ƒ{len(data['train_texts'])}, éªŒè¯{len(data['val_texts'])}, æµ‹è¯•{len(data['test_texts'])}")
    
    # 3. è®­ç»ƒæ¨¡å‹
    logger.info("ğŸ”¥ å¼€å§‹è®­ç»ƒ...")
    try:
        history = model.train(
            texts=data['train_texts'],
            y_train=data['y_train'],
            val_texts=data['val_texts'],
            y_val=data['y_val'],
            epochs=30,           # å¢åŠ è®­ç»ƒè½®æ•°
            batch_size=8,       # é€‚ä¸­çš„æ‰¹æ¬¡å¤§å°
            learning_rate=2e-5, # æ ‡å‡†BERTå­¦ä¹ ç‡
            weight_decay=0.01,
            warmup_steps=100,   # å¢åŠ é¢„çƒ­æ­¥æ•°
            early_stopping_patience=5
        )
        logger.info("âœ… è®­ç»ƒå®Œæˆ")
        
        # 4. è¯„ä¼°æ¨¡å‹
        logger.info("ğŸ“Š å¼€å§‹è¯„ä¼°...")
        metrics = model.evaluate(data['test_texts'], data['y_test'])
        
        logger.info("ğŸ“ˆ è¯„ä¼°ç»“æœ:")
        logger.info(f"  å‡†ç¡®ç‡: {metrics['accuracy']:.4f}")
        logger.info(f"  ç²¾ç¡®ç‡: {metrics['precision']:.4f}")
        logger.info(f"  å¬å›ç‡: {metrics['recall']:.4f}")
        logger.info(f"  F1åˆ†æ•°: {metrics['f1']:.4f}")
        
        # 5. ä¿å­˜æ¨¡å‹
        model_dir = Path('models')
        model_dir.mkdir(exist_ok=True)
        model_path = model_dir / "simple_bert_model.pkl"
        model.save_model(model_path)
        logger.info(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»å‡½æ•°"""
    logger.info("=" * 60)
    logger.info("ç®€åŒ–ç‰ˆBERTæ¨¡å‹è®­ç»ƒï¼ˆCPUå‹å¥½ï¼‰")
    logger.info("=" * 60)
    
    # æ£€æŸ¥PyTorch
    try:
        import torch
        logger.info(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
        if torch.cuda.is_available():
            logger.info(f"GPU: {torch.cuda.get_device_name(0)}")
        else:
            logger.info("ä½¿ç”¨CPUè®­ç»ƒ")
    except ImportError:
        logger.error("âŒ PyTorchæœªå®‰è£…")
        return
    
    # å¼€å§‹è®­ç»ƒ
    success = train_simple_model()
    
    if success:
        logger.info("ğŸ‰ è®­ç»ƒæˆåŠŸå®Œæˆï¼")
        logger.info("ğŸ’¡ ç°åœ¨å¯ä»¥ä½¿ç”¨ python ensemble_predictor.py è¿›è¡Œé¢„æµ‹")
    else:
        logger.error("âŒ è®­ç»ƒå¤±è´¥")
    
    logger.info("=" * 60)


if __name__ == "__main__":
    main()
